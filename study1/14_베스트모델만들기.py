# -*- coding: utf-8 -*-
"""14.베스트모델만들기.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1agcumg5FfIvP_BaCB6tX_Tg3omfJaNa_

# **모두의 딥러닝**
## 넷째마당-딥러닝 기본기 다지기

### 14장 베스트 모델 만들기
> 와인의 종류 예측하기

#### **모델업데이트하기**
> * keras.callbacks의 ModelCheckpoint를 이용해서 모니터링할 값을 지정하여 모델 저장에 옵션을 줄 수 있음
```
from keras.callbacks import ModelCheckpoint
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)
```
>> monitor: 모니터할 값 지정(acc, loss, val_loss, val_acc)  
verbose: 해당 함수의 진행 사항 출력 여부 지정(1=출력, 0=미출력)  
save_best_only=Treu: 모델이 앞서 저장한 모델보다 나아졌을 때만 저장  

#### **과적합이 되지 않도록 그래프로 확인하기**
> * 학습셋의 정확도는 epoch가 늘어날수록 좋아지지만, 테스트셋의 정확도는 어느정도 이상 시간이 흐르면 더 이상 좋아지지 않음. 
* 그래프를 통해 확인하며 적정한 epoch를 찾아보기

#### **학습 자동 중단(early stopping)**
> * 너무 많은 epoch은 overfitting을, 너무 적은 epoch은 underfitting을 발생시킴. -> epoch를 많이 주고, 특정시점에 멈추게 하자  
* 학습이 진행되어도 테스트셋의 오차가 줄지 않으면 학습을 멈춤.  
* keras.callbacks의 EarlyStopping 이용하여 자동 중단 설정하기.
```
from keras.callbacks import EarlyStopping
early_stopping_callback = EarlyStropping(monitor='val_loss', patience=100)
model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500, callbacks=[early_stopping_callback])
```
>> monitor: 모니터할 성능(performance measure) 지정  
mode: performance measure가 최소화 시켜야하는 것이면 min, 최대화 시켜야하는 것이면, max. (default = auto)  
patience: 테스트 오차가 좋아지지 않아도 몇 번까지 기다릴지 설정.
>>> 성능의 증가 기준, 또는 특정 값에 도달하게 할 수 있음
```
EarlyStopping(monitor='val_loss', min_delta = 1)   # val_loss가 1% 증가하지 않는 경우
EarlyStopping(monitor='val_loss', baseline = 0.4)  # val_loss가 0.4에 도달했을 경우
```
"""

from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping
from google.colab import files

import pandas as pd, numpy as np, io, os
import tensorflow as tf
import matplotlib.pyplot as plt

# seed 설정
seed = 0
np.random.seed(seed)
tf.set_random_seed(seed)

# 데이터 로드
uploaded = files.upload()
df_pre = pd.read_csv(io.StringIO(uploaded['wine.csv'].decode('utf-8')), header=None)
print(df_pre.shape)
df_pre.sample(5)

df = df_pre.sample(frac=.15)
dataset = df.values
X = dataset[:, 0:12]
Y = dataset[:, 12]

# 모델 설정
model = Sequential()
model.add(Dense(30, input_dim = 12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss = 'binary_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])

# 모델 저장 폴더 설정
MODEL_DIR = './model/'
if not os.path.exists(MODEL_DIR):
  os.mkdir(MODEL_DIR) 

# 모델 저장 조건 설정
modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

# 돌아가면 삭제
# # 모델 실행
# model.fit(X, Y, epochs = 200, batch_size = 200, validation_split=0.2, verbose=0, callbacks=[checkpointer])

# # 결과 출력
# print("\n Accuracy: %.4f" % (model.evaluate(X, Y)[1]))

# 모델 실행 및 저장
history = model.fit(X, Y, epochs = 3500, batch_size = 500, validation_split=0.33, callbacks=[checkpointer])

# 테스트셋으로 실험 결과의 오차 값을 저장
y_vloss = history.history['val_loss']
# 학습셋으로 측정한 정확도의 값을 저장
y_acc = history.history['acc']

# 결과 그래프로 그려보기
# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시
x_len = np.arange(len(y_acc))
plt.plot(x_len, y_vloss, "o", c = "red", markersize = 3)
plt.plot(x_len, y_acc, "o", c = "blue", markersize = 3)
plt.show()

from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping
from google.colab import files

import pandas as pd, numpy as np, os, tensorflow as tf, io

# seed 값 설정
seed = 0
np.random.seed(seed)
tf.set_random_seed(seed)

# 데이터 불러오기
uploaded = files.upload()
df_pre = reaa_csv(io.StringIO(uploaded['wine.csv'].decode('utf-8')), header = None)
df = df_pre.sample(frac = 0.15)      # 전체 샘플의 15%만 사용
dataset = df.values
X = dataset[:, 0:12]
Y = dataset[:, 12]

# 모델 설정
model = Sequential()
model.add(Dense(30, input_dim = 12, activation = 'relu'))
model.add(Dense(12, activation = 'relu'))
model.add(Dense(8, activation = 'relu'))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(loss = 'binary_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])

# 모델 저장 폴더 만들기
MODEL_DIR = './model/'
if not os.path.exists(MODEL_DIR):
  os.mkdir(MODEL_DIR)

modelpath = "./model/{epoch:02d}-{val_loss:.4f}.hdf5"

# 모델 업데이트 및 저장
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

#학습 자동 중단 설정
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)

model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, verbose=0, callbacks=[checkpointer, early_stopping_callback])

"""전체 반복값(epochs)을 3500으로 설정했으나 682회만 수행. 이후 100번가량 모델이 나아지지 않자 학습 자동 중단."""